{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP5NdADiULYnSrOodbdKv3u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LINA-LY/DetectionandTracking/blob/CODE/DetectionandTracking2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qv5vaqmCcXpq"
      },
      "outputs": [],
      "source": [
        "# Object Detection and Tracking System for Google Colab\n",
        "# Complete system with YOLO, tracking, and real-time capabilities\n",
        "\n",
        "# ========================================\n",
        "# INSTALL REQUIRED LIBRARIES\n",
        "# ========================================\n",
        "\n",
        "# Install essential packages\n",
        "!pip install ultralytics  # YOLOv8\n",
        "!pip install opencv-python\n",
        "!pip install pillow\n",
        "!pip install numpy\n",
        "!pip install matplotlib\n",
        "!pip install pandas\n",
        "!pip install torch torchvision\n",
        "!pip install supervision  # For tracking and visualization\n",
        "\n",
        "# For video processing\n",
        "!apt update &> /dev/null\n",
        "!apt install ffmpeg &> /dev/null\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import torch\n",
        "from ultralytics import YOLO\n",
        "import supervision as sv\n",
        "from collections import defaultdict\n",
        "import time\n",
        "import os\n",
        "from IPython.display import display, clear_output\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ========================================\n",
        "# YOLO OBJECT DETECTION CLASS\n",
        "# ========================================\n",
        "\n",
        "class ObjectDetector:\n",
        "    def __init__(self, model_size='n'):\n",
        "        \"\"\"\n",
        "        Initialize YOLO object detector\n",
        "        model_size options: 'n' (nano), 's' (small), 'm' (medium), 'l' (large), 'x' (extra large)\n",
        "        \"\"\"\n",
        "        print(f\"Loading YOLOv8{model_size} model...\")\n",
        "        self.model = YOLO(f'yolov8{model_size}.pt')\n",
        "        self.class_names = self.model.names\n",
        "        print(f\"Model loaded! Can detect {len(self.class_names)} different objects.\")\n",
        "\n",
        "    def detect_objects(self, image_path_or_array, confidence=0.5):\n",
        "        \"\"\"Detect objects in a single image\"\"\"\n",
        "        try:\n",
        "            # Run detection\n",
        "            results = self.model(image_path_or_array, conf=confidence)\n",
        "\n",
        "            detections = []\n",
        "            for result in results:\n",
        "                boxes = result.boxes\n",
        "                if boxes is not None:\n",
        "                    for box in boxes:\n",
        "                        # Extract box coordinates\n",
        "                        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
        "                        confidence = box.conf[0].cpu().numpy()\n",
        "                        class_id = int(box.cls[0].cpu().numpy())\n",
        "                        class_name = self.class_names[class_id]\n",
        "\n",
        "                        detections.append({\n",
        "                            'bbox': [int(x1), int(y1), int(x2), int(y2)],\n",
        "                            'confidence': float(confidence),\n",
        "                            'class_id': class_id,\n",
        "                            'class_name': class_name\n",
        "                        })\n",
        "\n",
        "            return detections, results[0].plot()\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Detection failed: {str(e)}\")\n",
        "            return [], None\n",
        "\n",
        "    def show_detections(self, image_path, confidence=0.5):\n",
        "        \"\"\"Display image with detection results\"\"\"\n",
        "        detections, annotated_image = self.detect_objects(image_path, confidence)\n",
        "\n",
        "        if annotated_image is not None:\n",
        "            plt.figure(figsize=(12, 8))\n",
        "            plt.imshow(cv2.cvtColor(annotated_image, cv2.COLOR_BGR2RGB))\n",
        "            plt.axis('off')\n",
        "            plt.title(f'Detected {len(detections)} objects')\n",
        "            plt.show()\n",
        "\n",
        "            # Print detection details\n",
        "            print(f\"\\nDetection Results:\")\n",
        "            print(\"-\" * 50)\n",
        "            for i, det in enumerate(detections):\n",
        "                print(f\"{i+1}. {det['class_name']}: {det['confidence']:.2f}\")\n",
        "\n",
        "        return detections\n",
        "\n",
        "# ========================================\n",
        "# OBJECT TRACKING CLASS\n",
        "# ========================================\n",
        "\n",
        "class ObjectTracker:\n",
        "    def __init__(self, model_size='n'):\n",
        "        \"\"\"Initialize object tracker with YOLO + ByteTracker\"\"\"\n",
        "        self.detector = ObjectDetector(model_size)\n",
        "        self.tracker = sv.ByteTrack()\n",
        "        self.trace_annotator = sv.TraceAnnotator()\n",
        "        self.box_annotator = sv.BoxAnnotator()\n",
        "        self.label_annotator = sv.LabelAnnotator()\n",
        "\n",
        "        # Tracking statistics\n",
        "        self.track_history = defaultdict(list)\n",
        "        self.object_counts = defaultdict(int)\n",
        "\n",
        "    def process_frame(self, frame, confidence=0.5):\n",
        "        \"\"\"Process a single frame for detection and tracking\"\"\"\n",
        "        # Run YOLO detection\n",
        "        results = self.detector.model(frame, conf=confidence)[0]\n",
        "\n",
        "        # Convert to supervision format\n",
        "        detections = sv.Detections.from_ultralytics(results)\n",
        "\n",
        "        # Update tracker\n",
        "        detections = self.tracker.update_with_detections(detections)\n",
        "\n",
        "        # Store tracking history\n",
        "        for tracker_id, bbox in zip(detections.tracker_id, detections.xyxy):\n",
        "            self.track_history[tracker_id].append(bbox)\n",
        "\n",
        "        # Create labels for annotation\n",
        "        labels = []\n",
        "        for class_id, tracker_id, conf in zip(detections.class_id, detections.tracker_id, detections.confidence):\n",
        "            class_name = self.detector.class_names[class_id]\n",
        "            labels.append(f\"#{tracker_id} {class_name} {conf:.2f}\")\n",
        "\n",
        "        # Annotate frame\n",
        "        annotated_frame = self.box_annotator.annotate(frame.copy(), detections)\n",
        "        annotated_frame = self.label_annotator.annotate(annotated_frame, detections, labels)\n",
        "        annotated_frame = self.trace_annotator.annotate(annotated_frame, detections)\n",
        "\n",
        "        return annotated_frame, detections\n",
        "\n",
        "    def get_tracking_stats(self):\n",
        "        \"\"\"Get tracking statistics\"\"\"\n",
        "        stats = {\n",
        "            'total_tracked_objects': len(self.track_history),\n",
        "            'active_tracks': len([k for k, v in self.track_history.items() if len(v) > 0]),\n",
        "            'track_lengths': {k: len(v) for k, v in self.track_history.items()},\n",
        "        }\n",
        "        return stats\n",
        "\n",
        "# ========================================\n",
        "# VIDEO PROCESSING CLASS\n",
        "# ========================================\n",
        "\n",
        "class VideoProcessor:\n",
        "    def __init__(self, model_size='n'):\n",
        "        \"\"\"Initialize video processor\"\"\"\n",
        "        self.tracker = ObjectTracker(model_size)\n",
        "        self.fps_counter = 0\n",
        "        self.start_time = time.time()\n",
        "\n",
        "    def process_video_file(self, video_path, output_path=None, max_frames=None):\n",
        "        \"\"\"Process video file and save results\"\"\"\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "        # Get video properties\n",
        "        fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "        print(f\"Video info: {width}x{height}, {fps} FPS, {total_frames} frames\")\n",
        "\n",
        "        # Setup video writer if output path provided\n",
        "        if output_path:\n",
        "            fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "            out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "        frame_count = 0\n",
        "        processed_frames = []\n",
        "\n",
        "        try:\n",
        "            while True:\n",
        "                ret, frame = cap.read()\n",
        "                if not ret:\n",
        "                    break\n",
        "\n",
        "                # Process frame\n",
        "                annotated_frame, detections = self.tracker.process_frame(frame)\n",
        "                processed_frames.append(annotated_frame)\n",
        "\n",
        "                # Write frame if output specified\n",
        "                if output_path:\n",
        "                    out.write(annotated_frame)\n",
        "\n",
        "                frame_count += 1\n",
        "\n",
        "                # Progress update\n",
        "                if frame_count % 30 == 0:  # Every 30 frames\n",
        "                    progress = (frame_count / total_frames) * 100\n",
        "                    print(f\"Processed {frame_count}/{total_frames} frames ({progress:.1f}%)\")\n",
        "\n",
        "                # Stop if max frames reached\n",
        "                if max_frames and frame_count >= max_frames:\n",
        "                    break\n",
        "\n",
        "        finally:\n",
        "            cap.release()\n",
        "            if output_path:\n",
        "                out.release()\n",
        "\n",
        "        print(f\"Video processing complete! Processed {frame_count} frames\")\n",
        "\n",
        "        # Return statistics\n",
        "        stats = self.tracker.get_tracking_stats()\n",
        "        stats['processed_frames'] = frame_count\n",
        "        stats['processing_fps'] = frame_count / (time.time() - self.start_time)\n",
        "\n",
        "        return processed_frames, stats\n",
        "\n",
        "    def process_webcam(self, duration_seconds=30):\n",
        "        \"\"\"Process webcam feed (for local environments)\"\"\"\n",
        "        print(\"Note: Webcam processing works best in local Python environments\")\n",
        "        print(\"In Colab, upload a video file instead\")\n",
        "\n",
        "        # This would work in local environment\n",
        "        \"\"\"\n",
        "        cap = cv2.VideoCapture(0)\n",
        "        start_time = time.time()\n",
        "\n",
        "        while time.time() - start_time < duration_seconds:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            annotated_frame, detections = self.tracker.process_frame(frame)\n",
        "\n",
        "            cv2.imshow('Object Tracking', annotated_frame)\n",
        "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "                break\n",
        "\n",
        "        cap.release()\n",
        "        cv2.destroyAllWindows()\n",
        "        \"\"\"\n",
        "\n",
        "# ========================================\n",
        "# ANALYSIS AND VISUALIZATION TOOLS\n",
        "# ========================================\n",
        "\n",
        "class DetectionAnalyzer:\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize detection analyzer\"\"\"\n",
        "        self.detection_history = []\n",
        "\n",
        "    def analyze_detections(self, detections_list):\n",
        "        \"\"\"Analyze detection results across multiple frames\"\"\"\n",
        "        if not detections_list:\n",
        "            return {}\n",
        "\n",
        "        # Count objects by class\n",
        "        class_counts = defaultdict(int)\n",
        "        confidence_scores = defaultdict(list)\n",
        "\n",
        "        for detections in detections_list:\n",
        "            if hasattr(detections, 'class_id'):\n",
        "                for class_id, conf in zip(detections.class_id, detections.confidence):\n",
        "                    class_name = YOLO('yolov8n.pt').names[class_id]\n",
        "                    class_counts[class_name] += 1\n",
        "                    confidence_scores[class_name].append(conf)\n",
        "\n",
        "        # Calculate statistics\n",
        "        stats = {}\n",
        "        for class_name, count in class_counts.items():\n",
        "            avg_confidence = np.mean(confidence_scores[class_name])\n",
        "            stats[class_name] = {\n",
        "                'total_detections': count,\n",
        "                'avg_confidence': avg_confidence,\n",
        "                'min_confidence': min(confidence_scores[class_name]),\n",
        "                'max_confidence': max(confidence_scores[class_name])\n",
        "            }\n",
        "\n",
        "        return stats\n",
        "\n",
        "    def create_detection_report(self, stats, save_path=None):\n",
        "        \"\"\"Create detailed detection report\"\"\"\n",
        "        if not stats:\n",
        "            print(\"No detection statistics available\")\n",
        "            return\n",
        "\n",
        "        # Create DataFrame\n",
        "        df_data = []\n",
        "        for class_name, class_stats in stats.items():\n",
        "            df_data.append({\n",
        "                'Object Class': class_name,\n",
        "                'Total Detections': class_stats['total_detections'],\n",
        "                'Average Confidence': f\"{class_stats['avg_confidence']:.3f}\",\n",
        "                'Min Confidence': f\"{class_stats['min_confidence']:.3f}\",\n",
        "                'Max Confidence': f\"{class_stats['max_confidence']:.3f}\"\n",
        "            })\n",
        "\n",
        "        df = pd.DataFrame(df_data)\n",
        "        df = df.sort_values('Total Detections', ascending=False)\n",
        "\n",
        "        print(\"ðŸ“Š OBJECT DETECTION ANALYSIS REPORT\")\n",
        "        print(\"=\" * 50)\n",
        "        print(df.to_string(index=False))\n",
        "\n",
        "        if save_path:\n",
        "            df.to_csv(save_path, index=False)\n",
        "            print(f\"\\nReport saved to: {save_path}\")\n",
        "\n",
        "        return df\n",
        "\n",
        "    def plot_detection_statistics(self, stats):\n",
        "        \"\"\"Create visualization of detection statistics\"\"\"\n",
        "        if not stats:\n",
        "            print(\"No statistics to plot\")\n",
        "            return\n",
        "\n",
        "        # Prepare data\n",
        "        classes = list(stats.keys())\n",
        "        counts = [stats[cls]['total_detections'] for cls in classes]\n",
        "        confidences = [stats[cls]['avg_confidence'] for cls in classes]\n",
        "\n",
        "        # Create subplots\n",
        "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "        # Detection counts\n",
        "        ax1.bar(classes, counts, color='skyblue', alpha=0.7)\n",
        "        ax1.set_title('Object Detection Counts')\n",
        "        ax1.set_xlabel('Object Class')\n",
        "        ax1.set_ylabel('Number of Detections')\n",
        "        ax1.tick_params(axis='x', rotation=45)\n",
        "\n",
        "        # Average confidence scores\n",
        "        ax2.bar(classes, confidences, color='lightcoral', alpha=0.7)\n",
        "        ax2.set_title('Average Confidence Scores')\n",
        "        ax2.set_xlabel('Object Class')\n",
        "        ax2.set_ylabel('Confidence Score')\n",
        "        ax2.tick_params(axis='x', rotation=45)\n",
        "        ax2.set_ylim(0, 1)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "# ========================================\n",
        "# DEMO AND TESTING FUNCTIONS\n",
        "# ========================================\n",
        "\n",
        "def demo_image_detection():\n",
        "    \"\"\"Demo: Object detection on sample images\"\"\"\n",
        "    print(\"ðŸŽ¯ IMAGE DETECTION DEMO\")\n",
        "    print(\"=\" * 40)\n",
        "\n",
        "    # Initialize detector\n",
        "    detector = ObjectDetector('n')  # Using nano model for speed\n",
        "\n",
        "    # You can test with URLs or uploaded images\n",
        "    print(\"Testing with sample image...\")\n",
        "\n",
        "    # For testing, you can use these sample images:\n",
        "    sample_images = [\n",
        "        \"https://ultralytics.com/images/bus.jpg\",\n",
        "        \"https://ultralytics.com/images/zidane.jpg\"\n",
        "    ]\n",
        "\n",
        "    for i, img_url in enumerate(sample_images):\n",
        "        print(f\"\\n--- Sample Image {i+1} ---\")\n",
        "        try:\n",
        "            detections = detector.show_detections(img_url, confidence=0.4)\n",
        "            print(f\"Found {len(detections)} objects!\")\n",
        "        except Exception as e:\n",
        "            print(f\"Could not process image: {e}\")\n",
        "\n",
        "def demo_video_processing():\n",
        "    \"\"\"Demo: Video processing setup\"\"\"\n",
        "    print(\"ðŸŽ¬ VIDEO PROCESSING DEMO\")\n",
        "    print(\"=\" * 40)\n",
        "\n",
        "    print(\"To process a video:\")\n",
        "    print(\"1. Upload your video file to Colab\")\n",
        "    print(\"2. Use the following code:\")\n",
        "    print(\"\"\"\n",
        "    # Initialize processor\n",
        "    processor = VideoProcessor('n')\n",
        "\n",
        "    # Process video\n",
        "    frames, stats = processor.process_video_file(\n",
        "        'your_video.mp4',\n",
        "        'output_tracked.mp4',\n",
        "        max_frames=100  # Limit for demo\n",
        "    )\n",
        "\n",
        "    # Analyze results\n",
        "    analyzer = DetectionAnalyzer()\n",
        "    detection_stats = analyzer.analyze_detections(frames)\n",
        "    analyzer.create_detection_report(detection_stats)\n",
        "    \"\"\")\n",
        "\n",
        "def create_detection_interface():\n",
        "    \"\"\"Interactive interface for object detection\"\"\"\n",
        "    print(\"ðŸš€ OBJECT DETECTION & TRACKING SYSTEM\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    detector = ObjectDetector('n')\n",
        "\n",
        "    while True:\n",
        "        print(\"\\nOptions:\")\n",
        "        print(\"1. Detect objects in image\")\n",
        "        print(\"2. Process video file\")\n",
        "        print(\"3. Show available object classes\")\n",
        "        print(\"4. Run image detection demo\")\n",
        "        print(\"5. Exit\")\n",
        "\n",
        "        choice = input(\"\\nEnter your choice (1-5): \").strip()\n",
        "\n",
        "        if choice == '1':\n",
        "            img_path = input(\"Enter image path or URL: \").strip()\n",
        "            confidence = float(input(\"Enter confidence threshold (0.1-1.0): \") or \"0.5\")\n",
        "\n",
        "            print(\"Processing image...\")\n",
        "            detections = detector.show_detections(img_path, confidence)\n",
        "\n",
        "        elif choice == '2':\n",
        "            print(\"Video processing requires uploading a video file to Colab first.\")\n",
        "            video_path = input(\"Enter video file path: \").strip()\n",
        "\n",
        "            if os.path.exists(video_path):\n",
        "                processor = VideoProcessor('n')\n",
        "                output_path = f\"tracked_{os.path.basename(video_path)}\"\n",
        "\n",
        "                print(\"Processing video... This may take a while.\")\n",
        "                frames, stats = processor.process_video_file(\n",
        "                    video_path,\n",
        "                    output_path,\n",
        "                    max_frames=100\n",
        "                )\n",
        "\n",
        "                print(f\"âœ… Video processed! Output saved as: {output_path}\")\n",
        "                print(f\"ðŸ“Š Statistics: {stats}\")\n",
        "            else:\n",
        "                print(\"âŒ Video file not found!\")\n",
        "\n",
        "        elif choice == '3':\n",
        "            print(\"\\nðŸ“‹ Available Object Classes:\")\n",
        "            print(\"-\" * 30)\n",
        "            for i, (class_id, class_name) in enumerate(detector.class_names.items()):\n",
        "                print(f\"{class_id}: {class_name}\")\n",
        "                if i > 0 and (i + 1) % 10 == 0:  # Show 10 at a time\n",
        "                    if input(\"\\nPress Enter to continue or 'q' to stop: \") == 'q':\n",
        "                        break\n",
        "\n",
        "        elif choice == '4':\n",
        "            demo_image_detection()\n",
        "\n",
        "        elif choice == '5':\n",
        "            print(\"Thank you for using the Object Detection System!\")\n",
        "            break\n",
        "\n",
        "        else:\n",
        "            print(\"Invalid choice. Please try again.\")\n",
        "\n",
        "# ========================================\n",
        "# MAIN EXECUTION\n",
        "# ========================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"ðŸŽ¯ OBJECT DETECTION AND TRACKING SYSTEM\")\n",
        "    print(\"=\" * 50)\n",
        "    print(\"Initializing system...\")\n",
        "\n",
        "    # Run demo first\n",
        "    demo_image_detection()\n",
        "\n",
        "    # Start interactive interface\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    create_detection_interface()"
      ]
    }
  ]
}